# GLM Provider Spec

## 1ï¸âƒ£ æ¦‚è¿°

ä¸º Wisadel Agent ç³»ç»Ÿå®ç°æ™ºè°± GLM Providerï¼Œä½œä¸º MiniMax Provider çš„å¹³è¡Œæ›¿ä»£æ–¹æ¡ˆï¼Œæä¾›åŸºäºæ™ºè°± GLM API çš„ LLM èƒ½åŠ›ã€‚

---

## 2ï¸âƒ£ æ ¸å¿ƒç›®æ ‡

1. **Provider æ¥å£**ï¼šå®ç° smolagents çš„ `Model` æ¥å£
2. **API å°è£…**ï¼šå°è£…æ™ºè°± GLM API è°ƒç”¨ï¼Œç»Ÿä¸€é”™è¯¯å¤„ç†
3. **æ¶ˆæ¯è½¬æ¢**ï¼šå°† smolagents `ChatMessage` æ ¼å¼è½¬æ¢ä¸º GLM API æ ¼å¼
4. **å¯æ›¿æ¢æ€§**ï¼šä¸ MinimaxProvider ä¿æŒä¸€è‡´çš„æ¥å£ï¼Œå¯æ— ç¼åˆ‡æ¢
5. **é…ç½®çµæ´»**ï¼šæ”¯æŒè‡ªå®šä¹‰æ¨¡å‹åç§°å’Œ API å‚æ•°

---

## 3ï¸âƒ£ Goals / Non-Goals

### âœ… Goals

1. å®ç° smolagents `Model` æ¥å£
2. å°è£…æ™ºè°± GLM API è°ƒç”¨ï¼ˆä½¿ç”¨ OpenAI SDK å…¼å®¹æ¥å£ï¼‰
3. æ”¯æŒ ChatMessage åˆ° GLM API æ ¼å¼çš„åŒå‘è½¬æ¢
4. ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œå¼‚å¸¸å°è£…
5. æ”¯æŒå¸¸ç”¨çš„ GLM æ¨¡å‹ï¼ˆglm-4, glm-4-flash ç­‰ï¼‰
6. Lazy initialization çš„ API client
7. ä¸ MinimaxProvider ä¿æŒæ¥å£ä¸€è‡´æ€§

### âŒ Non-Goals

* ä¸æ”¯æŒ GLM çš„å¤šæ¨¡æ€èƒ½åŠ›ï¼ˆå›¾åƒã€è§†é¢‘ç­‰ï¼‰- MVP é˜¶æ®µ
* ä¸æ”¯æŒ GLM çš„å‡½æ•°è°ƒç”¨ï¼ˆfunction callingï¼‰- MVP é˜¶æ®µ
* ä¸æ”¯æŒæµå¼å“åº”ï¼ˆstreamingï¼‰- MVP é˜¶æ®µ
* ä¸å®ç°å¤æ‚çš„é‡è¯•é€»è¾‘ - ä¾èµ– SDK
* ä¸å¤„ç† token è®¡æ•°å’Œè®¡è´¹ - ç”±è°ƒç”¨æ–¹ç®¡ç†

---

## 4ï¸âƒ£ API é€‰å‹

æ™ºè°± GLM æä¾›å¤šç§ API æ¥å£æ–¹å¼ï¼š

| æ¥å£æ–¹å¼ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‰ç”¨ |
|---------|------|------|------|
| **zai åŒ…ï¼ˆZhipuAiClientï¼‰** | å·²é›†æˆåœ¨é¡¹ç›®ä¸­ï¼ŒåŸç”Ÿæ”¯æŒï¼Œæ— éœ€é¢å¤–ä¾èµ– | ç›¸å¯¹å°ä¼— | âœ… **æœ€ç»ˆé€‰å‹** |
| OpenAI SDK å…¼å®¹æ¥å£ | ç”Ÿæ€æˆç†Ÿï¼Œä»£ç ç®€å•ï¼ŒSDK å®Œå–„ | éœ€è¦é¢å¤–å®‰è£…ä¾èµ– | âŒ |
| å®˜æ–¹ zhipuai SDK | åŸç”Ÿæ”¯æŒï¼Œæ–‡æ¡£å®Œæ•´ | ç‹¬ç«‹ä¾èµ–ï¼Œä¸ zai é‡å¤ | âŒ |
| Anthropic SDK å…¼å®¹æ¥å£ | ä¸ MiniMax å®ç°ä¸€è‡´ | æ™ºè°±å¯èƒ½ä¸æä¾›æ­¤æ¥å£ | âŒ |

**æœ€ç»ˆé€‰å‹**ï¼š**zai åŒ…ï¼ˆZhipuAiClientï¼‰**

### ç†ç”±

1. **å·²é›†æˆ**ï¼šé¡¹ç›®ä¸­å·²ç»ä½¿ç”¨äº† `zai` åŒ…ï¼Œæ— éœ€é¢å¤–å®‰è£…ä¾èµ–
2. **åŸç”Ÿæ”¯æŒ**ï¼šZhipuAiClient åŸç”Ÿæ”¯æŒæ™ºè°± GLM API
3. **æ¥å£ç®€æ´**ï¼šæä¾›ç±»ä¼¼ OpenAI SDK çš„æ¥å£é£æ ¼
4. **å‡å°‘ä¾èµ–**ï¼šé¿å…å¼•å…¥é¢å¤–çš„ SDK ä¾èµ–

---

## 5ï¸âƒ£ æ ¸å¿ƒæ¥å£è®¾è®¡

### 5.1 ç±»å®šä¹‰

```python
class GLMProvider(Model):
    """
    æ™ºè°± GLM Provider

    å®ç° smolagents çš„ Model æ¥å£ï¼Œå°è£…æ™ºè°± GLM API è°ƒç”¨
    ä½¿ç”¨ zai åŒ…ï¼ˆZhipuAiClientï¼‰
    """

    def __init__(self, api_key: str, model: str = "glm-4-flash"):
        """
        åˆå§‹åŒ– GLM Provider

        Args:
            api_key: æ™ºè°± API Key
            model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ glm-4-flashï¼‰
                   å¯é€‰: glm-4, glm-4-flash, glm-4-plus ç­‰
        """

    def generate(
        self,
        messages: List[ChatMessage],
        stop_sequences: Optional[List[str]] = None,
        response_format: Optional[Dict[str, str]] = None,
        tools_to_call_from: Optional[List] = None,
        **kwargs
    ) -> ChatMessage:
        """
        è°ƒç”¨ GLM APIï¼Œè¿”å› ChatMessage
        """

    def __call__(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 2000,
        **kwargs
    ) -> str:
        """
        è°ƒç”¨ GLM APIï¼Œè¿”å›å®Œæ•´å“åº”æ–‡æœ¬
        """
```

### 5.2 æ¶ˆæ¯æ ¼å¼è½¬æ¢

**è¾“å…¥**ï¼šsmolagents `ChatMessage` æ ¼å¼
```python
ChatMessage(
    role=MessageRole.USER,
    content="ç”¨æˆ·è¾“å…¥æ–‡æœ¬"
)
```

**è¾“å‡º**ï¼šzai API æ ¼å¼ï¼ˆOpenAI-likeï¼‰
```python
{
    "role": "user",
    "content": "ç”¨æˆ·è¾“å…¥æ–‡æœ¬"
}
```

**ç³»ç»Ÿæ¶ˆæ¯å¤„ç†**ï¼š
- smolagents: `ChatMessage(role=MessageRole.SYSTEM, content="...")`
- zai API: ä½œä¸º messages æ•°ç»„çš„ä¸€ä¸ªå…ƒç´ ï¼Œrole ä¸º "system"

### 5.3 API è°ƒç”¨å‚æ•°

```python
{
    "model": "glm-4-flash",
    "messages": [...],
    "max_tokens": 4096,
    "temperature": 0.7  # å¯é€‰
}
```

---

## 6ï¸âƒ£ å®ç°ç»†èŠ‚

### 6.1 ä¾èµ–ç®¡ç†

```python
# ä½¿ç”¨ zai åŒ…
from zai import ZhipuAiClient
from smolagents.models import Model, ChatMessage, MessageRole
```

**requirements.txt**:
```
zai  # é¡¹ç›®å·²æœ‰ï¼Œæ— éœ€æ–°å¢
```

### 6.2 Client åˆå§‹åŒ–ï¼ˆLazyï¼‰

```python
@property
def client(self) -> ZhipuAiClient:
    """Lazy init client"""
    if self._client is None:
        self._client = ZhipuAiClient(api_key=self.api_key)
    return self._client
```

### 6.3 æ¶ˆæ¯è½¬æ¢é€»è¾‘

```python
# åœ¨ generate() æ–¹æ³•å†…éƒ¨è½¬æ¢
api_messages: List[Dict[str, str]] = []

for msg in messages:
    if msg.role == MessageRole.ASSISTANT:
        api_messages.append({
            "role": "assistant",
            "content": msg.content or ""
        })
    elif msg.role == MessageRole.USER:
        api_messages.append({
            "role": "user",
            "content": msg.content or ""
        })
    elif msg.role == MessageRole.SYSTEM:
        api_messages.append({
            "role": "system",
            "content": msg.content or ""
        })
    else:
        api_messages.append({
            "role": str(msg.role),
            "content": msg.content or ""
        })
```

### 6.4 å“åº”å¤„ç†

```python
# æå–æ–‡æœ¬å†…å®¹
text_content = ""
if response.choices:
    text_content = response.choices[0].message.content or ""

return ChatMessage(
    role=MessageRole.ASSISTANT,
    content=text_content,
    raw=response
)
```

### 6.5 é”™è¯¯å¤„ç†

```python
try:
    # è½¬æ¢ä¸º ChatMessage æ ¼å¼
    chat_messages = []
    for msg in messages:
        role = MessageRole(msg["role"]) if msg["role"] in ["user", "assistant", "system"] else MessageRole.USER
        chat_messages.append(ChatMessage(role=role, content=msg["content"]))

    # ä¼ é€’å‚æ•°åˆ° generate æ–¹æ³•
    response = self.generate(
        chat_messages,
        temperature=temperature,
        max_tokens=max_tokens,
        **kwargs
    )
    return response.content.strip()

except Exception as e:
    raise RuntimeError(f"GLM API è°ƒç”¨å¤±è´¥: {str(e)}") from e
```

---

## 7ï¸âƒ£ æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

| æ¨¡å‹åç§° | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|---------|------|---------|
| **glm-4-flash** | å¿«é€Ÿæ¨¡å‹ï¼Œä½å»¶è¿Ÿ | MVP é»˜è®¤ï¼Œæ—¥å¸¸æ¶¦è‰²ä»»åŠ¡ |
| glm-4 | æ ‡å‡†æ¨¡å‹ | å¹³è¡¡æ€§èƒ½å’Œè´¨é‡ |
| glm-4-plus | å¢å¼ºæ¨¡å‹ | å¤æ‚ä»»åŠ¡ï¼Œé«˜è´¨é‡è¾“å‡º |

**MVP é˜¶æ®µé»˜è®¤**ï¼š`glm-4-flash`ï¼ˆå¿«é€Ÿã€ä½æˆæœ¬ï¼‰

---

## 8ï¸âƒ£ ä½¿ç”¨ç¤ºä¾‹

### 8.1 åŸºç¡€ä½¿ç”¨

```python
from agent.providers import GLMProvider
from smolagents.models import ChatMessage, MessageRole

# åˆå§‹åŒ– Provider
provider = GLMProvider(
    api_key="your-api-key",
    model="glm-4-flash"
)

# æ„å»ºæ¶ˆæ¯
messages = [
    ChatMessage(
        role=MessageRole.SYSTEM,
        content="ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬æ¶¦è‰²åŠ©æ‰‹"
    ),
    ChatMessage(
        role=MessageRole.USER,
        content="å¸®æˆ‘æ¶¦è‰²è¿™æ®µæ–‡æœ¬ï¼š..."
    )
]

# è°ƒç”¨ API
response = provider.generate(messages)
print(response.content)
```

### 8.2 ä¸ Agent é›†æˆ

```python
from agent import Wisadel
from agent.providers import GLMProvider

# ä½¿ç”¨ GLM Provider
model = GLMProvider(
    api_key="your-api-key",
    model="glm-4-flash"
)

# åˆ›å»º Agent
agent = Wisadel(model=model)

# è¿è¡Œä»»åŠ¡
result = agent.run("è¯·æ¶¦è‰²è¿™æ®µæ–‡æœ¬ï¼š...")
print(result)
```

---

## 9ï¸âƒ£ ä¸ MinimaxProvider çš„å¯¹æ¯”

| ç‰¹æ€§ | MinimaxProvider | GLMProvider |
|------|----------------|-------------|
| **SDK** | Anthropic SDK | zai (ZhipuAiClient) |
| **API é£æ ¼** | Anthropic Messages API | OpenAI-like Chat Completions |
| **Base URL** | https://api.minimaxi.com/anthropic | æ— éœ€æŒ‡å®šï¼ˆå†…ç½®ï¼‰ |
| **é»˜è®¤æ¨¡å‹** | MiniMax-M2.1 | glm-4-flash |
| **æ¶ˆæ¯æ ¼å¼** | Anthropic MessageParam | OpenAI-like ChatCompletion |
| **å“åº”æå–** | response.content[0].text | response.choices[0].message.content |
| **ç³»ç»Ÿæ¶ˆæ¯** | system å‚æ•°ï¼ˆç‹¬ç«‹ï¼‰ | messages æ•°ç»„ä¸­ |

**æ¥å£ä¸€è‡´æ€§**ï¼š
- âœ… éƒ½å®ç° `Model` æ¥å£
- âœ… éƒ½æ”¯æŒ `generate()` å’Œ `__call__()`
- âœ… éƒ½è¿”å› `ChatMessage`
- âœ… å¯æ— ç¼åˆ‡æ¢ï¼Œæ— éœ€ä¿®æ”¹ Agent ä»£ç 

---

## ğŸ”Ÿ MVP éªŒè¯æŒ‡æ ‡

- [ ] `GLMProvider` æˆåŠŸå®ç° `Model` æ¥å£
- [ ] èƒ½å¤Ÿæ­£å¸¸è°ƒç”¨æ™ºè°± GLM APIï¼Œè¿”å›å“åº”
- [ ] `ChatMessage` å’Œ API æ ¼å¼è½¬æ¢æ­£ç¡®
- [ ] ç³»ç»Ÿæ¶ˆæ¯ï¼ˆsystem promptï¼‰æ­£ç¡®ä¼ é€’
- [ ] é”™è¯¯å¤„ç†å®Œå–„ï¼Œå¼‚å¸¸ä¿¡æ¯æ¸…æ™°
- [ ] ä¸ `MinimaxProvider` æ¥å£ä¿æŒä¸€è‡´
- [ ] å¯åœ¨ `Wisadel` Agent ä¸­æ— ç¼åˆ‡æ¢ä½¿ç”¨
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒåŠŸèƒ½

---

## 1ï¸âƒ£1ï¸âƒ£ æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

```python
def test_glm_provider_init():
    """æµ‹è¯• Provider åˆå§‹åŒ–"""
    provider = GLMProvider(api_key="test-key")
    assert provider.api_key == "test-key"
    assert provider.model == "glm-4-flash"

def test_glm_provider_generate():
    """æµ‹è¯• generate æ–¹æ³•"""
    provider = GLMProvider(api_key="test-key")
    messages = [
        ChatMessage(role=MessageRole.USER, content="Hello")
    ]
    response = provider.generate(messages)
    assert isinstance(response, ChatMessage)
    assert response.role == MessageRole.ASSISTANT

def test_glm_provider_call():
    """æµ‹è¯• __call__ æ–¹æ³•"""
    provider = GLMProvider(api_key="test-key")
    messages = [{"role": "user", "content": "Hello"}]
    response = provider(messages)
    assert isinstance(response, str)
```

### é›†æˆæµ‹è¯•

```python
def test_glm_with_wisadel():
    """æµ‹è¯• GLM Provider ä¸ Wisadel é›†æˆ"""
    model = GLMProvider(
        api_key=os.getenv("GLM_API_KEY"),
        model="glm-4-flash"
    )
    agent = Wisadel(model=model)
    result = agent.run("æµ‹è¯•æ–‡æœ¬")
    assert result is not None
```

---

## 1ï¸âƒ£2ï¸âƒ£ é…ç½®ç®¡ç†

### ç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶
GLM_API_KEY=your-glm-api-key
GLM_MODEL=glm-4-flash  # å¯é€‰ï¼Œé»˜è®¤ glm-4-flash
```

### åŠ è½½é…ç½®

```python
import os
from dotenv import load_dotenv

load_dotenv()

provider = GLMProvider(
    api_key=os.getenv("GLM_API_KEY"),
    model=os.getenv("GLM_MODEL", "glm-4-flash")
)
```

---

## 1ï¸âƒ£3ï¸âƒ£ æ–‡ä»¶ç»“æ„

```
packages/windows-app/agent/
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ __init__.py           # å¯¼å‡º GLMProvider, MinimaxProvider
â”‚   â”œâ”€â”€ minimax_provider.py   # MiniMax Providerï¼ˆå·²å®ç°ï¼‰
â”‚   â””â”€â”€ glm_provider.py       # GLM Providerï¼ˆæ–°å¢ï¼‰
â””â”€â”€ tests/
    â””â”€â”€ test_glm_provider.py  # GLM Provider æµ‹è¯•ï¼ˆæ–°å¢ï¼‰
```

---

## 1ï¸âƒ£4ï¸âƒ£ å®æ–½ä¼˜å…ˆçº§

### P0 - æ ¸å¿ƒåŠŸèƒ½ï¼ˆMVP å¿…é¡»ï¼‰

- [ ] å®ç° `GLMProvider` ç±»
- [ ] å®ç° `generate()` æ–¹æ³•
- [ ] å®ç° `__call__()` æ–¹æ³•
- [ ] æ¶ˆæ¯æ ¼å¼è½¬æ¢
- [ ] é”™è¯¯å¤„ç†
- [ ] åŸºç¡€å•å…ƒæµ‹è¯•

### P1 - å®Œå–„æ€§ï¼ˆMVP åï¼‰

- [ ] å®Œæ•´çš„å•å…ƒæµ‹è¯•è¦†ç›–
- [ ] é›†æˆæµ‹è¯•
- [ ] æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆå¦‚ connection poolï¼‰

### P2 - å¢å¼ºåŠŸèƒ½ï¼ˆæœªæ¥æ‰©å±•ï¼‰

- [ ] æµå¼å“åº”æ”¯æŒ
- [ ] Function calling æ”¯æŒ
- [ ] å¤šæ¨¡æ€æ”¯æŒï¼ˆå›¾åƒè¾“å…¥ï¼‰
- [ ] Token è®¡æ•°å’Œæˆæœ¬ä¼°ç®—

---

## 1ï¸âƒ£5ï¸âƒ£ é£é™©å’Œæ³¨æ„äº‹é¡¹

### API ç¨³å®šæ€§

- âš ï¸ æ™ºè°± GLM API å¯èƒ½æœ‰ç‰ˆæœ¬æ›´æ–°ï¼Œéœ€å…³æ³¨å…¼å®¹æ€§
- âš ï¸ OpenAI SDK ç‰ˆæœ¬æ›´æ–°å¯èƒ½å½±å“æ¥å£

### é”™è¯¯å¤„ç†

- âš ï¸ éœ€è¦å¤„ç†ç½‘ç»œè¶…æ—¶ã€é™æµã€é…é¢ç­‰é”™è¯¯
- âš ï¸ API Key è¿‡æœŸæˆ–æ— æ•ˆçš„å‹å¥½æç¤º

### æ€§èƒ½è€ƒè™‘

- âš ï¸ API å“åº”å»¶è¿Ÿå¯èƒ½å½±å“ç”¨æˆ·ä½“éªŒ
- âš ï¸ è€ƒè™‘æ·»åŠ è¶…æ—¶è®¾ç½®å’Œé‡è¯•æœºåˆ¶

---

## 1ï¸âƒ£6ï¸âƒ£ å‚è€ƒèµ„æ–™

- [æ™ºè°± AI å¼€æ”¾å¹³å°æ–‡æ¡£](https://open.bigmodel.cn/dev/api)
- [OpenAI SDK æ–‡æ¡£](https://github.com/openai/openai-python)
- [smolagents æ–‡æ¡£](https://github.com/huggingface/smolagents)
- [Wisadel é¡¹ç›® - MinimaxProvider å®ç°](../packages/windows-app/agent/providers/minimax_provider.py)
